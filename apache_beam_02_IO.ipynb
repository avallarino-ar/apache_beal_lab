{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbLwcf7P98xD"
   },
   "source": [
    "### Pipeline - Using Map\n",
    "#### step by step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149633CM,Marco,10,Accounts,1-01-2019\n",
      "212539MU,Rebekah,10,Accounts,1-01-2019\n",
      "231555ZZ,Itoe,10,Accounts,1-01-2019\n",
      "503996WI,Edouard,10,Accounts,1-01-2019\n",
      "704275DC,Kyle,10,Accounts,1-01-2019\n",
      "957149WC,Kyle,10,Accounts,1-01-2019\n",
      "241316NX,Kumiko,10,Accounts,1-01-2019\n",
      "796656IE,Gaston,10,Accounts,1-01-2019\n",
      "331593PS,Beryl,20,HR,1-01-2019\n",
      "560447WH,Olga,20,HR,1-01-2019\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "# Read / Write pipeline:\n",
    "attendance_count = (\n",
    "    p1\n",
    "    |beam.io.ReadFromText('data/dept_data.txt')\n",
    "    \n",
    "    |beam.io.WriteToText('output/output_map1')\n",
    ")\n",
    "\n",
    "p1.run()\n",
    "\n",
    "# visualize output\n",
    "!{('head -n 10 output/output_map1-00000-of-00001')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['149633CM', 'Marco', '10', 'Accounts', '1-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019']\n",
      "['331593PS', 'Beryl', '20', 'HR', '1-01-2019']\n",
      "['560447WH', 'Olga', '20', 'HR', '1-01-2019']\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "# Split the data:\n",
    "attendance_count = (\n",
    "    p1\n",
    "    |beam.io.ReadFromText('data/dept_data.txt')\n",
    "    |beam.Map(lambda record: record.split(','))\n",
    "    |beam.io.WriteToText('output/output_split')\n",
    "  \n",
    ")\n",
    "\n",
    "p1.run()\n",
    "\n",
    "# visualize output\n",
    "!{('head -n 10 output/output_split-00000-of-00001')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['149633CM', 'Marco', '10', 'Accounts', '1-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '2-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '2-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '2-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '2-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '2-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '2-01-2019']\n",
      "['718737IX', 'Ayumi', '10', 'Accounts', '2-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '3-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '3-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '3-01-2019']\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "# Split + filter the data:\n",
    "attendance_count = (\n",
    "    p1\n",
    "    |beam.io.ReadFromText('data/dept_data.txt')\n",
    "    |beam.Map(lambda record: record.split(','))\n",
    "    |beam.Filter(lambda record: record[3] == 'Accounts')\n",
    "    |beam.io.WriteToText('output/output_filter')\n",
    "  \n",
    ")\n",
    "\n",
    "p1.run()\n",
    "\n",
    "# visualize output\n",
    "!{('head -n 20 output/output_filter-00000-of-00001')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Marco', 1)\n",
      "('Rebekah', 1)\n",
      "('Itoe', 1)\n",
      "('Edouard', 1)\n",
      "('Kyle', 1)\n",
      "('Kyle', 1)\n",
      "('Kumiko', 1)\n",
      "('Gaston', 1)\n",
      "('Marco', 1)\n",
      "('Rebekah', 1)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "# Split + filter + key-value:\n",
    "attendance_count = (\n",
    "    p1\n",
    "    |beam.io.ReadFromText('data/dept_data.txt')\n",
    "    |beam.Map(lambda record: record.split(','))\n",
    "    |beam.Filter(lambda record: record[3] == 'Accounts')\n",
    "    |beam.Map(lambda record: (record[1], 1))\n",
    "    |beam.io.WriteToText('output/output_kv')\n",
    "  \n",
    ")\n",
    "\n",
    "p1.run()\n",
    "\n",
    "# visualize output\n",
    "!{('head -n 10 output/output_kv-00000-of-00001')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Marco', 31)\n",
      "('Rebekah', 31)\n",
      "('Itoe', 31)\n",
      "('Edouard', 31)\n",
      "('Kyle', 62)\n",
      "('Kumiko', 31)\n",
      "('Gaston', 31)\n",
      "('Ayumi', 30)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as pipe:\n",
    "    # Split + filter + key-value + Sum by key:\n",
    "    attendance_count = (\n",
    "        pipe\n",
    "        |\"Read file\" >> beam.io.ReadFromText('data/dept_data.txt')\n",
    "        |\"Split\"     >> beam.Map(lambda record: record.split(','))\n",
    "        |\"Filter\"    >> beam.Filter(lambda record: record[3] == 'Accounts')\n",
    "        |\"KV\"        >> beam.Map(lambda record: (record[1], 1))     # |beam.Map(lambda record: (record[1], 1))  # By ID\n",
    "        |\"Sum\"       >> beam.CombinePerKey(sum)   # GropuBy + Combiner + Reducer\n",
    "        |\"Output\"    >> beam.io.WriteToText('output/output_sum')\n",
    "    )\n",
    "\n",
    "# visualize output\n",
    "!{('head -n 10 output/output_sum-00000-of-00001')}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "apache_beam_01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
